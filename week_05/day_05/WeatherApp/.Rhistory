group_by (mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{max(.x, na.rm = TRUE)}))
min_data <- data %>%
filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{min(.x, na.rm = TRUE)}))
met_data = pivot_longer(data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "data")
met_avg = pivot_longer(avg_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_avg_data")
met_min = pivot_longer(min_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_min_data")
met_max = pivot_longer(max_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_max_data")
avg_merge = merge(met_avg,met_max)
avg_merge = merge(avg_merge,met_min)
rm(data,avg_data,max_data,min_data)
rm (met_avg,met_max,met_min)
all_met = left_join(met_data,avg_merge, by = c("mm","param")) %>%
mutate(anom_data = data - mnth_avg_data)
all_met %>%
# create decimal year data for plotting
mutate(dec_year = yyyy+(mm-0.5)/12) %>%
# select param to plot
filter(param==input$param) %>%
ggplot() +
#geom_line(aes(x=dec_year, y = data)) +
#geom_line(aes(x=dec_year, y = mnth_avg_data), col = "gray") +
geom_line(aes(x = dec_year, y = anom_data), col = "red")
all_met %>%
# create decimal year data for plotting
mutate(dec_year = yyyy+(mm-0.5)/12) %>%
# select param to plot
filter(param==input$param) %>%
ggplot() +
geom_line(aes(x=dec_year, y = data, col = "blue")) +
all_met %>%
# create decimal year data for plotting
mutate(dec_year = yyyy+(mm-0.5)/12) %>%
# select param to plot
filter(param==input$param) %>%
ggplot() +
geom_line(aes(x=dec_year, y = data, col = "blue"))
all_met %>%
# create decimal year data for plotting
mutate(dec_year = yyyy+(mm-0.5)/12) %>%
# select param to plot
filter(param==input$param) %>%
ggplot() +
geom_line(aes(x=dec_year, y = data))
source("~/.active-rstudio-document", echo=TRUE)
location_list = c("lerwick","paisley","eastbourne")
iloc=1
filename <- str_c(location_list[iloc],"data.txt")
header <- extract_header(filename)
data <- read_data(filename)
read_data <- function(filename){
#read data
data <- read.table(here::here("raw_data",filename),
header = FALSE, skip = 7, #skip over header rows
comment.char = "P", # removes lines that have Provisional
fill = TRUE,
flush = TRUE,
col.names = header$col_names) #take this from header
data$tmax <- strip_strings(data$tmax,c("\\*","\\#"))
data$tmax <- as.double(data$tmax)
data$tmin <- strip_strings(data$tmin,c("\\*","\\#"))
data$tmin <- as.double(data$tmin)
data$af <- strip_strings(data$af,c("\\*","\\#"))
data$af <- as.double(data$af)
data$rain <- strip_strings(data$rain,c("\\*","\\#"))
data$rain <- as.double(data$rain)
data$sun <- strip_strings(data$sun,c("\\*","\\#"))
data$sun <- as.double(data$sun)
data %>%
mutate(location = str_to_lower(header$location))
}
data <- read_data(filename)
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
for (iloc in location_list){
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data,
iloc=1
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
all_data <- data,
all_data <- data
all_header <- header
bind_rows(all_data,data)
bind_rows(all_data,data)
bind_rows(all_data,data)
alldata <- bind_rows(all_data,data)
alldata <- bind_rows(all_data,data)
alldata <- bind_rows(all_data,data)
for (iloc in location_list){
iloc=1
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- bind_rows(all_data,data)
}
}
source("~/Documents/codeclan_homework_SarahHughes/codeclan_homework_SarahHughes/week_05/day_05/WeatherApp/read_met_data.R", echo=TRUE)
for (iloc in location_list){
#iloc=1
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- bind_rows(all_data,data)
}
}
iloc=2
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
alldata <- bind_rows(all_data,data)
alldata <- merge(all_data,data)
for (iloc in location_list){
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- merge(all_data,data)
allheader <- merge(all_header,header)
}
}
for (iloc in 1:length(location_list)){
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- merge(all_data,data)
allheader <- merge(all_header,header)
}
}
## Script for reading in met data
# Note that data input ignores 'provisional' tags on data
# Data from most recent year is likely to be provisional
#  the file structure is like this
#  header line1 with location
#  header line2 including position
#  header line3
#  header line4
#  header line5
#  yyyy  mm   tmax    tmin      af    rain     sun
#              degC    degC    days      mm   hours
# data quality flags are * for estimated data and # for different sun detector
# for testing - parameters that will maybe be passed?
input <- list(location = "lerwick",
param = "tmax",
baseline = "1991-2020")
input$st_year = as.numeric(str_sub(input$baseline,1,4))
input$end_year = as.numeric(str_sub(input$baseline,6,9))
# Set up libraries needed -------------------------------------------------
library(tidyverse)
library(janitor)
library(colorfindr)
library(lubridate)
# Section 1 - Define function for reading in header -----------------------
# data is in a fixed width format with 7 header lines
# this code reads header and extracts the necessary metadata from it
extract_header <- function(filename){
header_txt <- read_lines(here::here("raw_data",filename),n_max = 7)
location_txt <- header_txt[1]
position_lat <- str_extract(header_txt[2], "Lat\\s.{6}") #identify lat string
position_lat <- as.numeric(str_remove(position_lat,"Lat ")) #strip lat string
position_lon <- str_extract(header_txt[2], "Lon\\s.{6}") #identify lon string
position_lon <- as.numeric(str_remove(position_lon,"Lon ")) #strip lon string
col_txt <- str_split(header_txt[6], pattern = "\\s{1,}", simplify = TRUE)
col_txt <- col_txt[2:8]
param_txt <- str_split(header_txt[7], pattern = "\\s{1,}", simplify = TRUE)
param_txt <- param_txt[2:5]
header <- list("location" = location_txt,
"param_names" = param_txt,
"col_names" = col_txt,
"latitude" = position_lat,
"longitude" = position_lon)
}
# Section 4 Define function for reading a met data file -------------------
read_data <- function(filename){
#read data
data <- read.table(here::here("raw_data",filename),
header = FALSE, skip = 7, #skip over header rows
comment.char = "P", # removes lines that have Provisional
fill = TRUE,
flush = TRUE,
col.names = header$col_names) #take this from header
data$tmax <- strip_strings(data$tmax,c("\\*","\\#"))
data$tmax <- as.double(data$tmax)
data$tmin <- strip_strings(data$tmin,c("\\*","\\#"))
data$tmin <- as.double(data$tmin)
data$af <- strip_strings(data$af,c("\\*","\\#"))
data$af <- as.double(data$af)
data$rain <- strip_strings(data$rain,c("\\*","\\#"))
data$rain <- as.double(data$rain)
data$sun <- strip_strings(data$sun,c("\\*","\\#"))
data$sun <- as.double(data$sun)
data %>%
mutate(location = str_to_lower(header$location))
}
# Section 2 Define function for stripping strings -------------------------
# some data values are tagged with * to indicate provisional data
# we are treating this data in the same way as non-provissional data so need
# will just ignore this tag. some sunshine data are also tagged with # to
# indicate instrument used. again we are ignoring this
strip_strings <- function(old_column, strings){
cleaned <- old_column
# order strings longest first so "string within string" is not a problem
order <- sort(nchar(strings), decreasing=TRUE, index.return=TRUE)
strings <- strings[order$ix]
for (badstring in strings){
cleaned <- str_remove(cleaned,str_c(" ",badstring))
#adding this doesnt allow for a string to be 'embedded'
cleaned <- str_trim(cleaned)
}
return(cleaned)
}
# Section 4 - Identify data files available ------------------------------------
# will expand this section to identify available data from a directory
# for now its just a list
location_list = c("lerwick","paisley","eastbourne")
filename <- str_c(location_list[iloc],"data.txt")
iloc=1
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- merge(all_data,data)
allheader <- merge(all_header,header)
}
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- merge(all_data,data)
allheader <- merge(all_header,header)
}
location_list[iloc]
iloc=2
filename <- str_c(location_list[iloc],"data.txt")
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
alldata <- merge(all_data,data)
allheader <- merge(all_header,header)
}
allheader <- merge(all_header,header)
allheader <- bindrows(all_header,header)
allheader <- bind_rows(all_header,header)
alldata <- merge(all_data,data)
alldata <- left_join(all_data,data)
all_data % filter(location =="paisley")
for (iloc in 1:length(location_list)){
#iloc=2
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
all_data <- left_join(all_data,data)
all_header <- bind_rows(all_header,header)
}
}
1:length(location_list)
iloc=3
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
all_data <- data
all_header <- header
all_data <- left_join(all_data,data)
all_header <- bind_rows(all_header,header)
all_data <- left_join(all_data,data)
all_header <-left_join(all_header,header)
all_header$location <- paste(all_header$location,header$location)
for (iloc in 1:length(location_list)){
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
all_data <- left_join(all_data,data)
all_header$location <- paste(all_header$location,header$location)
all_header$longitude <- paste(all_header$longitude,header$longitude)
all_header$latitude <- paste(all_header$latitude,header$latitude)
}
}
all_data %>%
filter(location == "Paisley")
rm (all_data,all_header,data,header)
rm(alldata)
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
location_list = c("lerwick","paisley","eastbourne")
iloc
iloc <- 1
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc==1){
all_data <- data
all_header <- header
} else {
all_data <- left_join(all_data,data)
all_header$location <- paste(all_header$location,header$location)
all_header$longitude <- paste(all_header$longitude,header$longitude)
all_header$latitude <- paste(all_header$latitude,header$latitude)
iloc == 1
iloc == 1
if (iloc == 1){
all_data <- data
all_header <- header
} else {
all_data <- left_join(all_data,data)
all_header$location <- paste(all_header$location,header$location)
all_header$longitude <- paste(all_header$longitude,header$longitude)
all_header$latitude <- paste(all_header$latitude,header$latitude)
}
iloc <- 2
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc == 1){
all_data <- data
all_header <- header
} else {
all_data <- left_join(all_data,data)
all_header$location <- paste(all_header$location,header$location)
all_header$longitude <- paste(all_header$longitude,header$longitude)
all_header$latitude <- paste(all_header$latitude,header$latitude)
}
all_data %>%
filter(location == "Paisley")
all_data %>%
filter(location == "paisley")
View(all_data)
View(all_data)
all_data <- bind_rows(all_data,data)
View(all_data)
for (iloc in 1:length(location_list)){
filename <- str_c(location_list[iloc],"data.txt")
#first read header
header <- extract_header(filename)
#then read data
data <- read_data(filename)
if (iloc == 1){
all_data <- data
all_header <- header
} else {
all_data <- bind_rows(all_data,data)
all_header$location <- paste(all_header$location,header$location)
all_header$longitude <- paste(all_header$longitude,header$longitude)
all_header$latitude <- paste(all_header$latitude,header$latitude)
}
}
rm(header,data)
source("~/Documents/codeclan_homework_SarahHughes/codeclan_homework_SarahHughes/week_05/day_05/WeatherApp/read_met_data.R", echo=TRUE)
shiny::runApp()
runApp()
avg_data <- all_data %>%
#filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (location, mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{median(.x, na.rm = TRUE)}))
View(avg_data)
View(avg_data)
avg_data <- all_data %>%
#filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (location, mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{median(.x, na.rm = TRUE)}))
max_data <- all_data %>%
filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{max(.x, na.rm = TRUE)}))
min_data <- all_data %>%
filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{min(.x, na.rm = TRUE)}))
# merge averages back into file
met_data = pivot_longer(all_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "data")
avg_data <- all_data %>%
#filter(location == input$location) %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (location, mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{median(.x, na.rm = TRUE)}))
max_data <- all_data %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (location,mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{max(.x, na.rm = TRUE)}))
min_data <- all_data %>%
filter(yyyy >= input$st_year & yyyy < input$end_year) %>%
group_by (location, mm) %>%
select(-yyyy) %>%
summarise(across(where(is.numeric),
~{min(.x, na.rm = TRUE)}))
# merge averages back into file
met_data = pivot_longer(all_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "data")
met_avg = pivot_longer(avg_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_avg_data")
met_min = pivot_longer(min_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_min_data")
met_max = pivot_longer(max_data, c(tmax,tmin,af,rain,sun),
names_to = "param",
values_to = "mnth_max_data")
avg_merge = merge(met_avg,met_max)
avg_merge = merge(avg_merge,met_min)
rm(data,avg_data,max_data,min_data)
rm (met_avg,met_max,met_min)
all_met = left_join(met_data,avg_merge, by = c("mm","param")) %>%
mutate(anom_data = data - mnth_avg_data)
runApp()
unique(met_data$location)
unique(met_data$param)
runApp()
input$location_input
